
\chapter{Revisão de Literatura} 

    \section{IA na indústria de petroleo}
    
        O uso de IA na indústria de Exploração e Produção (E\&P) de petróleo tem sido extenso. Nas últimas décadas, a maioria das aplicações de IA na indústria envolve mineração de dados e redes neurais \cite{Bravo2014}. Um exemplo é o trabalho de \cite{Gudala2021} sobre a otimização das propriedades de fluxo de óleo pesado, utilizando redes neurais para otimizar parâmetros que influenciam o fluxo.
        
        Uma contribuição significativa vem da integração do conhecimento do domínio com estruturas digitais para aprimorar a tomada de decisões em tratamentos de fraturamento. Essa abordagem, demonstrada por \cite{Khan2024}, utiliza aprendizado de máquina para melhorar a eficiência operacional e reduzir custos.
        
        Outro desenvolvimento foi um fluxo de trabalho de aprendizado profundo proposto por \cite{Gohari2024}, com a geração de logs gráficos sintéticos de poços através da aplicação de aprendizado por transferência. Esses desenvolvimentos ilustram o potencial da IA em melhorar processos e a precisão e eficiência da análise de dados \cite{Rahmani2021}.
        
        Processamento de Linguagem Natural (PLN) situa-se na interseção da ciência da computação e linguística, representando um domínio dentro da inteligência artificial que visa permitir que computadores compreendam e processem a linguagem humana de maneira significativa e eficaz \cite{Liddy2001}. Este campo integra uma variedade de técnicas computacionais para analisar e representar texto em vários níveis de detalhe linguístico, buscando emular a compreensão da linguagem humana. Como uma área ativa de pesquisa, tradicionalmente o PLN emprega múltiplas camadas de análise linguística, cada uma contribuindo de forma única para a interpretação e geração de linguagem, encontrando aplicações práticas em diversos setores \cite{Liddy2001}.
        
        Na indústria de O\&G, a gestão de dados não estruturados, como textos, imagens e documentos, é crucial, com o Processamento de Linguagem Natural (PLN) e o Aprendizado de Máquina desempenhando papéis chave. Pesquisas de \cite{Antoniak2016} e \cite{Castineira2018} exploraram o uso de PLN para analisar riscos e relatórios de perfuração.
    
        \section{Modelos de Linguagem de Grande Escala (LLMs).}  
        
            Os LLMs são modelos avançados baseados em redes neurais projetados para entender e gerar textos semelhantes aos humanos. Eles utilizam a arquitetura Transformer, apresentada no artigo seminal "Attention is All You Need" por \cite{Vaswani2017}. Esta arquitetura depende de mecanismos de auto-atenção, permitindo que o modelo avalie efetivamente a importância de diferentes palavras em uma sentença.
            
            O surgimento dos LLMs tornou possível compreender e produzir informações textuais. Espera-se que esses sistemas revolucionem várias indústrias ao apoiar processos complexos de tomada de decisão. Os modelos GPT \cite{OpenAI2023}, em particular, aproveitam seu vasto conjunto de dados de treinamento para fornecer respostas semelhantes às humanas \cite{Mosser2024}, o que pode ser altamente benéfico em contextos que exigem compreensão e geração de linguagem natural.
            
            Como destacado por \cite{Singh2023}, a integração de soluções baseadas em LLMs, como chatbots conversacionais, oferece uma abordagem para otimizar operações em vários segmentos de negócios, incluindo perfuração, completação e produção. \cite{Singh2023} usa modelos LLMs para extrair, analisar e interpretar conjuntos de dados, permitindo a geração de insights e recomendações.
            
            Apesar de seu impacto generalizado, os modelos de linguagem não estão isentos de limitações. Em muitas aplicações específicas da indústria, as informações críticas necessárias são frequentemente proprietárias, não compartilhadas com terceiros e, portanto, ausentes dos dados de treinamento desses LLMs \cite{Mosser2024}. Essa lacuna significa que os modelos GPT podem não ter acesso às informações mais atualizadas ou sensíveis necessárias para certas tarefas. Além disso, devido à sua natureza probabilística, os LLMs podem experimentar alucinações, produzindo respostas confiantes, mas incorretas ou sem sentido, com base na entrada do usuário \cite{OpenAI2023}.
    
    
        \section{Tarefas de Pergunta e Resposta (Q\&A).}
        
            A tarefa de Pergunta e Resposta (Q\&A) representa um método para facilitar a transferência de conhecimento entre indivíduos dentro das organizações \cite{Iske2005}. Conceitualmente, os sistemas Q\&A são projetados para conectar indivíduos que possuem conhecimento específico com aqueles que buscam esse conhecimento por meio de um formato estruturado de pergunta e resposta.
            O papel do Q\&A no cenário da documentação, exemplificado por plataformas como o Stack Overflow, destaca sua importância em disciplinas técnicas \cite{Treude2011}. Esse entendimento pode orientar as organizações a tomarem decisões mais informadas sobre a implementação de tais sistemas para aprimorar a transferência de conhecimento e o aprendizado organizacional \cite{Iske2005}.
    
    
        \section{Tarefas Text-to-SQL}
        
            As tarefas de Text-to-SQL no contexto da inteligência artificial envolvem a tradução automática de perguntas ou comandos em linguagem natural para consultas SQL (Structured Query Language) estruturadas \cite{Qin2022}. Esta é uma área importante no processamento de linguagem natural (NLP), permitindo que os usuários interajam com bancos de dados usando linguagem comum, em vez de precisar saber como escrever consultas SQL complexas.
            
            A chegada de modelos de linguagem avançados como GPT-3 e GPT-4 \cite{OpenAI2023} marcou um salto significativo nas aplicações de Text-to-SQL \cite{Singh2023}, demonstrando capacidades notáveis no tratamento dessas tarefas. Isso pode ser atribuído ao seu extenso treinamento em conjuntos de dados diversificados \cite{Deng2021}, que incluem não apenas grandes volumes de texto, mas também dados estruturados como tabelas e código, permitindo ao modelo entender as relações intrincadas entre linguagem e estruturas de dados. O estudo de \cite{Deng2023} introduz um framework de pré-treinamento para tradução de texto para SQL, enfatizando o alinhamento entre texto e tabelas nas tarefas de Text-to-SQL.
        
        
        \section{Multi-Agent Setup} 
    
            Conforme demonstrado por \cite{xi2023rise}, a busca pela Inteligência Artificial Geral (AGI) tem se beneficiado significativamente do desenvolvimento de agentes baseados em LLM, capazes de percepção, tomada de decisão e ação em diversos cenários.        
            Seu estudo delineia uma estrutura fundamental para tais agentes, composta por componentes de cérebro, percepção e ação, que podem ser personalizados para várias aplicações, incluindo cenários de agente único, sistemas multi-agentes e colaboração humano-agente. 
            A pesquisa abrangente destaca o papel crucial dos LLMs no avanço em direção à AGI, sugerindo um horizonte promissor para a eficiência operacional e os processos de tomada de decisão em configurações organizacionais complexas \cite{xi2023rise}.
            \cite{Li2024} demonstrou que, através de um método de amostragem e votação, o desempenho dos LLMs escala com o número de agentes instanciados.
            Outro framework de código aberto é o AutoGen \cite{Wu2023}, que permite a criação de aplicações multi-agentes LLM, possibilitando a personalização em vários modos. Ele apoia diversas aplicações em campos como matemática, programação e pesquisa operacional, demonstrando sua eficácia por meio de estudos empíricos \cite{Wu2023}.

